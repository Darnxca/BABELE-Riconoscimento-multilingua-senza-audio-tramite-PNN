{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70068,"status":"ok","timestamp":1685042779220,"user":{"displayName":"CARMINE D'ANGELO","userId":"02677852198280047247"},"user_tz":-120},"id":"F-lAM7RD3qSe","outputId":"5bf9a76a-e58e-4e13-8e45-1d4cd78eb5b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# **Definizione librerie utili**"],"metadata":{"id":"O4BVW8wnlfdi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yo8NKpg6KD-U"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import math\n","import os\n","from pathlib import Path\n","from sklearn.decomposition import MiniBatchDictionaryLearning"]},{"cell_type":"markdown","source":["# Path principali delle cartelle in cui sono contenuti i file"],"metadata":{"id":"WO31AfMy7YUL"}},{"cell_type":"code","source":["path_principale = \"/content/drive/Shareddrives/Progetti FVAB 22 23 - VSR & BABELE/Gruppi/Gruppo 22/Progetto BABELE/\"\n","path_train = \"Train/\"\n","path_test = \"Test/\"\n","path_validation = \"Validation/\""],"metadata":{"id":"Ga_2_ANkO8Yh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Salvataggio lista di librerie e versioni installate**\n"],"metadata":{"id":"vVUTQY-pfj3S"}},{"cell_type":"code","source":["!pip freeze > \"/content/drive/Shareddrives/Progetti FVAB 22 23 - VSR & BABELE/Gruppi/Gruppo 22/Progetto BABELE/requirements_estrazioneSVD.txt\""],"metadata":{"id":"Eqd1O8Rxe_E3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h0DGakXtLYkw"},"source":["# **Generazione dei file in cui saranno contenute le path dei video**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0zXNzdmpBsT"},"outputs":[],"source":["import os\n","import glob\n","\n","# cartella contenente la path del dataset\n","dataset_path = \"/content/drive/Shareddrives/Progetti FVAB 22 23 - VSR & BABELE/Datasets/Dataset_2_BABELE/BABELE_Dataset/Dataset_split_subject_independent/Lips_video_10_seconds_division_train_test_val\"\n","\n","# cartella in cui salvare i file\n","folder_save = path_principale+\"FILE_PATH\"\n","\n","# Loop over all subfolders in folder_read\n","for subfolder in os.listdir(dataset_path):\n","    # Create a file with the subfolder's name in folder_save\n","    file_path = os.path.join(folder_save, subfolder + \"_babele_lips.txt\")\n","    \n","    # Open the file for writing\n","    with open(file_path, \"w\") as f:\n","        # Get a list of all files in the subfolder\n","        files = glob.glob(os.path.join(dataset_path, subfolder, \"*\"))\n","        \n","        # Write each file's path to the file\n","        for file in files:\n","            f.write(file + \"\\n\")\n"]},{"cell_type":"markdown","metadata":{"id":"GH7bRntSLggB"},"source":["# **Preprocessing dei video tramite codifica sparsa**\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["## **Impostazione parametri per la codifica sparsa e inizializzazione modello**\n"],"metadata":{"id":"iwUA85rCYqAv"}},{"cell_type":"code","source":["# Imposta i parametri per la codifica sparsa\n","# N.B La spiegazione dei parametri settati è riportata nella prossima cella \n","n_components = 1\n","alpha = 1\n","batch_size = 3\n","n_iter = 1000\n","shuffle = True\n","random_state = None\n","positive_dict = False\n","transform_algorithm = 'omp'\n","transform_alpha = None\n","transform_n_nonzero_coefs = None\n","\n","# Inizializza il modello di apprendimento del dizionario\n","dict_learning = MiniBatchDictionaryLearning(n_components=n_components,alpha=alpha,\n","                                            batch_size=batch_size, n_iter=n_iter, shuffle=shuffle,random_state=random_state,\n","                                            positive_dict=positive_dict, transform_algorithm=transform_algorithm,\n","                                            transform_alpha=transform_alpha,transform_n_nonzero_coefs=transform_n_nonzero_coefs)"],"metadata":{"id":"SwcGAXqbY0X_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","* n_components: Specifica il numero di componenti nel dizionario sparso. In questo caso, è impostato a 1, il che significa che si desidera un singolo componente nel dizionario.\n","* alpha: Parametro di regolarizzazione per il modello di apprendimento del dizionario. Controlla il livello di sparsità delle rappresentazioni sparse. Un valore più alto di alpha produce rappresentazioni più sparse.\n","* batch_size: La dimensione del batch utilizzata per l'apprendimento del dizionario. Indica il numero di campioni da utilizzare in ogni iterazione dell'algoritmo di apprendimento.\n","* n_iter: Il numero di iterazioni per l'apprendimento del dizionario. Specifica quante volte ripetere l'algoritmo di apprendimento.\n","* shuffle: Indica se i campioni devono essere mescolati prima di ogni iterazione. Se impostato su True, i campioni vengono mescolati casualmente per ogni iterazione.\n","* random_state: Il seed utilizzato dal generatore di numeri casuali. Se viene fornito un valore, garantisce la riproducibilità dell'apprendimento del dizionario.\n","* positive_dict: Specifica se il dizionario appreso deve essere vincolato ad avere solo valori non negativi.\n","* transform_algorithm: L'algoritmo utilizzato per calcolare la codifica sparsa dei campioni. In questo caso, è impostato su 'omp', che sta per Orthogonal Matching Pursuit.\n","* transform_alpha: Parametro di regolarizzazione per l'algoritmo di codifica sparsa. Controlla la sparsità delle rappresentazioni sparse. Se non viene fornito alcun valore, viene utilizzato il valore di alpha definito precedentemente.\n","* transform_n_nonzero_coefs: Il numero massimo di coefficienti non nulli nella rappresentazione sparsa di ogni campione. Se non viene fornito alcun valore, non viene impostato alcun limite.\n","\n"],"metadata":{"id":"4DZwdXuJaaLt"}},{"cell_type":"markdown","metadata":{"id":"8V2qWDnqJ7mB"},"source":["## **Lista contenente le path dei file dei video**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RbG8JeD33yJd"},"outputs":[],"source":["files_path = [\"/content/drive/Shareddrives/Progetti FVAB 22 23 - VSR & BABELE/Gruppi/Gruppo 22/Progetto BABELE/FILE_PATH/Test_babele_lips.txt\",\n","              \"/content/drive/Shareddrives/Progetti FVAB 22 23 - VSR & BABELE/Gruppi/Gruppo 22/Progetto BABELE/FILE_PATH/Train_babele_lips.txt\",\n","              \"/content/drive/Shareddrives/Progetti FVAB 22 23 - VSR & BABELE/Gruppi/Gruppo 22/Progetto BABELE/FILE_PATH/Validation_babele_lips.txt\"]"]},{"cell_type":"markdown","source":["## **Generazione dataset**"],"metadata":{"id":"sooloxgqlaSk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWuz3Kzayazd"},"outputs":[],"source":["from tqdm import tqdm\n","import pandas as pd\n","\n","for path_file in files_path:\n","\n","  with open(path_file, mode='r') as file:\n","\n","    video_data = []  # Lista di tutti i dati dei video\n","    \n","    linee = file.readlines()\n","\n","    csv_filename = os.path.basename(path_file)\n","    csv_filename_without_extension = csv_filename.split(\".\")[0] #per la creazione del dataset voglio un nome senza .txt\n","    estensione = \"_SVD.csv\"\n","\n","    if \"Validation\" in path_file:\n","      csv_path = path_principale+\"CSV_DATASET_CODIFICA_SPARSA/\"+path_validation + csv_filename_without_extension + estensione\n","    elif \"Train\" in path_file:\n","      csv_path = path_principale+\"CSV_DATASET_CODIFICA_SPARSA/\"+path_train + csv_filename_without_extension + estensione\n","    elif \"Test\" in path_file:\n","       csv_path = path_principale+\"CSV_DATASET_CODIFICA_SPARSA/\"+path_test + csv_filename_without_extension + estensione\n","    else:\n","      print(\"Qualcosa è andato storto!\")\n","      break\n","   \n","    for video_path in tqdm(linee, desc=\"Elaborazione video \" + csv_filename_without_extension, unit=\"video\"):\n","        video_path = video_path.strip() # Rimuovi il carattere di a capo dalla stringa\n","\n","        # Apre il video in input\n","        cap = cv2.VideoCapture(str(video_path))\n","\n","        filename = os.path.basename(video_path) #Nome del file video\n","        filename_without_extension = filename.split(\".\")[0] #per la creazione del dataset voglio un nome senza .avi\n","        components = filename.split(\"_\")[:-1] #splitto l'array in un altro per \"_\" e elimino \".avi\"\n","       \n","        target = int(components[0]) #Estrazione classe (lingua)\n","\n","        frame_data = {}\n","        frame_data['video-frame'] = filename_without_extension # Alla fine collego al nome del file il frame analizzato\n","        colonna = 0\n","\n","        # Inizializza la lista dei dati del video\n","        video_data_video = []\n","\n","        # Loop attraverso i frame del video\n","        while True:\n","            # Leggi il frame successivo\n","            ret, frame = cap.read()\n","          \n","            # Se non ci sono più frame, esci dal loop\n","            if not ret:\n","                break\n","            \n","            # Converti l'immagine in scala di grigi\n","            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            \n","            # Appiattisci l'immagine in un array 1D\n","            flat_frame = gray_frame.flatten()\n","            \n","            # Apprendi il dizionario sparsificato dal frame corrente\n","            dict_learning.partial_fit([flat_frame])\n","\n","        # Recupera il dizionario appreso\n","        dictionary = dict_learning.components_[0]\n","        array = np.array(dictionary)\n","        dizionario = {i: v for i, v in enumerate(array)}\n","        frame_data.update(dizionario)\n","\n","\n","        frame_data['target']= target\n","        \n","        # Aggiungi il dizionario alla lista dei dati del video\n","        video_data_video.append(frame_data)\n","\n","        # Aggiungi i dati del video alla lista di tutti i dati\n","        video_data.extend(video_data_video)\n","\n","        # Chiudi il video\n","        cap.release()\n","\n","    # Crea il dataframe dai dati di tutti i video e visualizzalo\n","    df = pd.DataFrame(video_data)\n","  \n","    # df_PCA = riduzione_PCA(df) \n","    # Visualizza il DataFrame \n","    display(df) \n","\n","    print(100*\"-\")\n","    print(\"Generazione del file csv \", csv_filename_without_extension, estensione)\n","    print(100*\"-\")\n","    df.to_csv(csv_path, index=False)\n","\n","    file.close()"]},{"cell_type":"markdown","metadata":{"id":"CPcufyNIA6DK"},"source":["# **Applicazione PCA per  ridurre i dataset**"]},{"cell_type":"markdown","metadata":{"id":"oNStA8wTGRqH"},"source":["## **Calcolo numero di componenti ottimale**\n","Si cerca di mantenere una percentuale significativa di varianza, ad esempio il 95%, ma questo può variare in base alle esigenze specifiche del problema."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EY7-yPvpGOZ2"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","def numero_componenti(df):\n","  # Seleziona solo le colonne numeriche per la PCA\n","  df_numeric = df.select_dtypes(include=[np.number])\n","\n","  # Crea l'oggetto PCA e fitalo ai dati numerici\n","  pca = PCA()\n","  pca.fit(df_numeric)\n","\n","  # Calcola la varianza cumulativa spiegata dalle componenti principali\n","  variance_cumulative = np.cumsum(pca.explained_variance_ratio_)\n","\n","  # Calcola il numero di componenti principali per mantenere il 95% di varianza\n","  n_components = np.argmax(variance_cumulative >= 0.95) + 1\n","\n","  print(f'Il numero di componenti principali del dataset per mantenere il 95% di varianza è {n_components}')\n","\n","  return  n_components"]},{"cell_type":"markdown","metadata":{"id":"VoEijqC1Gxbq"},"source":["## **Funzione che applica la PCA**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ixQU8zPG0uX"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","def riduzione_PCA(df,components=0):\n","  df_numeric = df.drop(['video-frame'], axis=1)\n","  df_numeric = df_numeric.drop(['target'], axis=1)\n","\n","  if components == 0:\n","    n_components = numero_componenti(df_numeric)\n","  else:\n","    n_components = components\n","\n","  pca = PCA(n_components=n_components)\n","  df_pca = pca.fit_transform(df_numeric)\n","\n","  df_result = pd.concat([df['video-frame'],  pd.DataFrame(df_pca), df['target']], axis=1)\n","\n","  return df_result\n"]},{"cell_type":"markdown","source":["## **Caricamento dataset  originali**"],"metadata":{"id":"kriBCRgulMNz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"phE99lO99TmS"},"outputs":[],"source":["import pandas as pd\n","\n","#Recupero dei vari csv\n","df_train = pd.read_csv(path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Train/Train_babele_lips_SVD.csv\")\n","df_test = pd.read_csv(path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Test/Test_babele_lips_SVD.csv\")\n","df_validation = pd.read_csv(path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Validation/Validation_babele_lips_SVD.csv\")\n"]},{"cell_type":"markdown","source":["## **Calcolo numero delle componenti per  la varianza al  95% per ogni dataset**"],"metadata":{"id":"ONi2K1bImkIq"}},{"cell_type":"code","source":["display(riduzione_PCA(df_train)) # varianza calcolata 8 \n","\n","display(riduzione_PCA(df_test))  # varianza calcolata 20\n","\n","display(riduzione_PCA(df_validation))  # varianza calcolata 4"],"metadata":{"id":"anS6nwlsYJ6Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Riduzione PCA a [4,8,20,40,60,80,120,160] componenti**\n","Nota: la scelta delle componenti si basa su di un range che va da 0 al min(n_samples, n_features), esempio: n_samples = 160 e n_features= 60000, abbiamo che il range in cui ci possiamo spostare è da 0 a 160"],"metadata":{"id":"ddW7sRYY5VqU"}},{"cell_type":"code","source":["num_componenti = [4,8,20,40,60,80,120,160]\n","\n","for componente in num_componenti:\n","  estensione = \"_SVD_\"+str(componente)+\"C.csv\"\n","\n","  train_path = path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Train/Train_babele_lips\" + estensione\n","  test_path = path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Test/Test_babele_lips\" + estensione\n","  val_path = path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Validation/Validation_babele_lips\" + estensione\n","\n","  print(100*\"-\")\n","  dtr = riduzione_PCA(df_train,componente)\n","  print(\"Generazione del file csv \", \"Train_babele_lips\", estensione)\n","  dtr.to_csv(train_path, index=False)\n","  print(100*\"-\")\n","\n","  print(100*\"-\")\n","  dte = riduzione_PCA(df_test,componente)\n","  print(\"Generazione del file csv \", \"Test_babele_lips\", estensione)\n","  dte.to_csv(test_path, index=False)\n","  print(100*\"-\")\n","\n","  print(100*\"-\")\n","  dva = riduzione_PCA(df_validation,componente)\n","  print(\"Generazione del file csv \", \"Validation_babele_lips\", estensione)\n","  dva.to_csv(val_path, index=False)\n","  print(100*\"-\")"],"metadata":{"id":"vOVjJaxE5h1t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fusione dataset BABELE (features + CODIFICA SPARSA)"],"metadata":{"id":"CYU5ZiQzxRtt"}},{"cell_type":"markdown","source":["Dopo aver estratto i valori della CODIFICA SPARSA dal video (prendiamo la codifica sparsa da 20 componenti), questi vengono uniti al dataset di features di 60 frames per ogni video."],"metadata":{"id":"B7dghNxXygsc"}},{"cell_type":"code","source":["import pandas as pd\n","\n","#Recupero dei vari csv\n","df_train_svd = pd.read_csv(path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Train/Train_babele_lips_SVD_20C.csv\")\n","df_test_svd = pd.read_csv(path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Test/Test_babele_lips_SVD_20C.csv\")\n","df_validation_svd = pd.read_csv(path_principale+\"CSV_DATASET_CODIFICA_SPARSA/Validation/Validation_babele_lips_SVD_20C.csv\")\n","\n","print(50*\"-\"+\"Train - CODIFICA_SPARSA\"+\"-\"*50)\n","print(df_train_svd)\n","print(50*\"-\"+\"Test - CODIFICA_SPARSA\"+\"-\"*50)\n","print(df_test_svd)\n","print(50*\"-\"+\"Validation - CODIFICA_SPARSA\"+\"-\"*50)\n","print(df_validation_svd)\n","\n","\n","df_train_features = pd.read_csv(path_principale+\"CSV_DATASET/Train/Train_babele_cityblock_60FPS.csv\")\n","df_test_features = pd.read_csv(path_principale+\"CSV_DATASET/Test/Test_babele_cityblock_60FPS.csv\")\n","df_validation_features = pd.read_csv(path_principale+\"CSV_DATASET/Validation/Validation_babele_cityblock_60FPS.csv\")\n","\n","print(50*\"-\"+\"Train - features\"+\"-\"*50)\n","print(df_train_features)\n","print(50*\"-\"+\"Test - features\"+\"-\"*50)\n","print(df_test_features)\n","print(50*\"-\"+\"Validation - features\"+\"-\"*50)\n","print(df_validation_features)\n","\n","# Unione dei dataset di validation\n","# Rimuove la colonna 'video-frame'e 'target' dal dataframe SVD\n","df_train_features.drop(['video-frame'], axis=1, inplace=True)\n","df_test_features.drop(['video-frame'], axis=1, inplace=True)\n","df_validation_features.drop(['video-frame'], axis=1, inplace=True)\n","\n","df_train_svd.drop(['target'], axis=1, inplace=True)\n","df_test_svd.drop(['target'], axis=1, inplace=True)\n","df_validation_svd.drop(['target'], axis=1, inplace=True)\n","\n","# Unione dei dataset di train\n","df_train_merged = pd.concat([df_train_svd, df_train_features], axis=1)\n","\n","# Unione dei dataset di test\n","df_test_merged = pd.concat([df_test_svd, df_test_features], axis=1)\n","\n","# Unione dei dataset di validation\n","df_validation_merged = pd.concat([df_validation_svd, df_validation_features], axis=1)\n","\n","\n","print(50*\"-\"+\"Train - features + codifica sparsa\"+\"-\"*50)\n","display(df_train_merged)\n","print(50*\"-\"+\"Test - features + codifica sparsa\"+\"-\"*50)\n","display(df_test_merged)\n","print(50*\"-\"+\"Validation - features + codifica sparsa\"+\"-\"*50)\n","display(df_validation_merged)\n","\n","print(\"Generazione del file csv -- Train_features+svd\")\n","df_train_merged.to_csv(path_principale+\"CSV_DATASET_MERGED/Train_features+svd.csv\", index=False)\n","print(\"Generazione del file csv -- Test_features+svd\")\n","df_test_merged.to_csv(path_principale+\"CSV_DATASET_MERGED/Test_features+svd.csv\", index=False)\n","print(\"Generazione del file csv -- Validation_features+svd\")\n","df_validation_merged.to_csv(path_principale+\"CSV_DATASET_MERGED/Validation_features+svd.csv\", index=False)\n","\n"],"metadata":{"id":"NKrNlCGvxcrI"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}